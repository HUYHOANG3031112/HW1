{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================\n",
    "Plot the decision surface of a decision tree on the iris dataset\n",
    "================================================================\n",
    "\n",
    "Plot the decision surface of a decision tree trained on pairs\n",
    "of features of the iris dataset.\n",
    "\n",
    "See :ref:`decision tree <tree>` for more information on the estimator.\n",
    "\n",
    "For each pair of iris features, the decision tree learns decision\n",
    "boundaries made of combinations of simple thresholding rules inferred from\n",
    "the training samples.\n",
    "\n",
    "This code was adapted from the example provided by scikit-learn, available at\n",
    "http://scikit-learn.org/stable/auto_examples/tree/plot_iris.html#example-tree-plot-iris-py\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Parameters\n",
    "n_classes = 3\n",
    "plot_colors = \"bry\"\n",
    "plot_step = 0.02\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "\n",
    "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
    "                                [1, 2], [1, 3], [2, 3]]):\n",
    "    # We only take the two corresponding features\n",
    "    X = iris.data[:, pair]  \n",
    "    y = iris.target\n",
    "\n",
    "    # Shuffle\n",
    "    # <array>.shape returns the dimensions of the array\n",
    "    # arange (start,stop,step) creates a 1-D vector\n",
    "    idx = np.arange(X.shape[0])  # returns an array from 0 to X.shape[0], or 150\n",
    "    np.random.seed(13)  # Seed the randomization \n",
    "    np.random.shuffle(idx)  # Shuffle in place based on the seeded randomization\n",
    "    \n",
    "    X = X[idx]   # re-sort X randomly based on IDX as indices\n",
    "    y = y[idx]\n",
    "\n",
    "    # Standardize\n",
    "    mean = X.mean(axis=0)    # Take the mean over the first axis (long axis)\n",
    "    std = X.std(axis=0)\n",
    "    X = (X - mean) / std   # Normalize to a 'normal distribution'\n",
    "\n",
    "    # Train\n",
    "    clf = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.subplot(2, 3, pairidx + 1)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    # Meshgrid creates coordinate grid from vectors of coordinates\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    # Ravel creates a 1-D view of the vector\n",
    "    # c_ concatenates 1D vectors into columns of a 2D array, basically\n",
    "    #    making xx.ravel() column 0, yy.ravel() column 1\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.xlabel(iris.feature_names[pair[0]])\n",
    "    plt.ylabel(iris.feature_names[pair[1]])\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "plt.suptitle(\"Decision surface of a decision tree using paired features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
